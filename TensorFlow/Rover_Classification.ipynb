{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rover_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVu3gvmPuBGy/8ekjl/M16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/AICrowd_Competition_Files/blob/main/TensorFlow/Rover_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la582oFS-727",
        "outputId": "d08fceb2-fcb9-4044-e832-d23e7d2a5e6d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Mar 27 01:44:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsDqRIdjiBO4"
      },
      "source": [
        "# Rover Classification \n",
        "Someone has mishandled the labeling of two Mars rover projects — Curiosity and Perseverance — we must classify them correctly.\n",
        "\n",
        "The given dataset contains images of two different rovers i.e. Curiosity and Perseverance of size 265x256 in jpg format. The images in **train.zip** and **val.zip**  have their labels i.e. which rover it is in **train.csv** and **val.csv**. The labels for the images in test.zip needs to be predicted.\n",
        "\n",
        "### Evaluation Criteria\n",
        "During evaluation F1 score is used as Primary Score and Accuracy Score as Secondary Score will be used to test the efficiency of the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEXuFQQj_JDs",
        "outputId": "70618080-d105-433c-a457-a13a3441704a"
      },
      "source": [
        "# Downloading the data and putting them inside a folder\n",
        "!pip install aicrowd-cli \n",
        "API_KEY = '166125ed5356c39ba63c026cf8cda906'\n",
        "!aicrowd login --api-key $API_KEY"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aicrowd-cli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/28/eaa46e7949fe877ca1481b8b72c205c511ce4ce5e81ada9111b51ff40e78/aicrowd_cli-0.1.1-py3-none-any.whl (42kB)\n",
            "\r\u001b[K     |███████▊                        | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hCollecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 7.8MB/s \n",
            "\u001b[?25hCollecting rich\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/e3/7929cc640f14bffc835bba5efb2f9177007e536429d9fe145765e5f221c4/rich-9.13.0-py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (2.23.0)\n",
            "Collecting requests-toolbelt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n",
            "Requirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (4.41.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->aicrowd-cli) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich->aicrowd-cli) (3.7.4.3)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->aicrowd-cli) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->aicrowd-cli) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->aicrowd-cli) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->aicrowd-cli) (2020.12.5)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: smmap, gitdb, gitpython, commonmark, colorama, rich, requests-toolbelt, aicrowd-cli\n",
            "Successfully installed aicrowd-cli-0.1.1 colorama-0.4.4 commonmark-0.9.1 gitdb-4.0.7 gitpython-3.1.14 requests-toolbelt-0.9.1 rich-9.13.0 smmap-4.0.0\n",
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g14iDYzq_1oq",
        "outputId": "4e33d20d-5967-48ce-f72e-b732de961824"
      },
      "source": [
        "# Downloading the datasets\n",
        "!aicrowd dataset download --challenge rover-classification -j 3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rsample_submission.csv:   0% 0.00/164k [00:00<?, ?B/s]\n",
            "\rtrain.csv:   0% 0.00/689k [00:00<?, ?B/s]\u001b[A\n",
            "\r                                         \r\u001b[A\rsample_submission.csv: 100% 164k/164k [00:00<00:00, 1.86MB/s]\n",
            "train.csv: 100% 689k/689k [00:00<00:00, 4.72MB/s]\n",
            "test.zip:   0% 0.00/66.5M [00:00<?, ?B/s]\n",
            "val.csv: 100% 65.0k/65.0k [00:00<00:00, 1.48MB/s]\n",
            "\n",
            "train.zip:   0% 0.00/266M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "val.zip:   0% 0.00/26.5M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "val.zip: 100% 26.5M/26.5M [00:01<00:00, 15.5MB/s]\n",
            "\n",
            "test.zip:  50% 33.6M/66.5M [00:05<00:05, 6.39MB/s]\n",
            "train.zip:  25% 67.1M/266M [00:05<00:18, 11.0MB/s]\u001b[A\n",
            "test.zip: 100% 66.5M/66.5M [00:08<00:00, 7.28MB/s]\n",
            "test.zip: 100% 66.5M/66.5M [00:08<00:00, 8.01MB/s]\n",
            "train.zip: 100% 266M/266M [00:18<00:00, 14.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npRNV-F_p9k"
      },
      "source": [
        "# Creating folders\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "\n",
        "!unzip train.zip  -d data/train\n",
        "!unzip val.zip -d data/val\n",
        "!unzip test.zip  -d data/test\n",
        "\n",
        "!mv train.csv data/train.csv\n",
        "!mv val.csv data/val.csv\n",
        "!mv sample_submission.csv data/sample_submission.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmBsiLLsBoaF",
        "outputId": "62f64cbd-125b-4fa9-a920-43635ffec1e1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-27 01:45:26--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9304 (9.1K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   9.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-27 01:45:26 (119 MB/s) - ‘helper_functions.py’ saved [9304/9304]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3OvnOx7BH_X"
      },
      "source": [
        "# Importing the needed packages \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from helper_functions import plot_loss_curves , make_confusion_matrix , compare_historys , walk_through_dir "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04sEyAGvCABw",
        "outputId": "2f536c38-d9a7-4de6-a0a4-f3ea350da3a2"
      },
      "source": [
        "# Looking inside the train directory\n",
        "walk_through_dir('data/train/')\n",
        "walk_through_dir('data/test/')\n",
        "walk_through_dir('data/val/')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 directories and 40000 images in 'data/train/'.\n",
            "There are 0 directories and 10000 images in 'data/test/'.\n",
            "There are 0 directories and 4000 images in 'data/val/'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95PMkKBICGes"
      },
      "source": [
        "# Let's get our csv files which will help us to label \n",
        "train_df = pd.read_csv('data/train.csv')\n",
        "val_df = pd.read_csv('data/val.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SsB2MNOSCp2-",
        "outputId": "d83417fc-1533-4ac3-d79b-548b97d3a21f"
      },
      "source": [
        "# Checking what's in the train_df\n",
        "train_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>curiosity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>curiosity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>curiosity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>perseverance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>curiosity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageID         label\n",
              "0        0     curiosity\n",
              "1        1     curiosity\n",
              "2        2     curiosity\n",
              "3        3  perseverance\n",
              "4        4     curiosity"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn-KLXm0bPTv",
        "outputId": "47a9af21-7bd7-4864-bad2-db6dce95d7f4"
      },
      "source": [
        "# How many unique classe are there? (and great there is not class imbalance)\n",
        "train_df['label'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "perseverance    20048\n",
              "curiosity       19952\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p79EvZJTCtxL"
      },
      "source": [
        "# Getting the train, test and val dir \n",
        "train_dir = 'data/train/'\n",
        "test_dir = 'data/test/'\n",
        "val_dir = 'data/val/'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD6wIwaYFFub",
        "outputId": "5f84e0f6-c915-40d2-edfc-7a5291564b3d"
      },
      "source": [
        "# Will look how the filenames look like \n",
        "import os \n",
        "print(os.listdir(train_dir)[:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['13794.jpg', '1058.jpg', '37500.jpg', '8855.jpg', '10105.jpg', '23535.jpg', '25702.jpg', '23006.jpg', '2752.jpg', '6572.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ31qUYDFTWa"
      },
      "source": [
        "In our dataframe we gotta add the extension `jpg` at the end to download the images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKcA_m8oFjJf"
      },
      "source": [
        "# Creating a function for making the action\n",
        "def append_ext(fn):\n",
        "    return f'{fn}.jpg'\n",
        "\n",
        "# Now applying them \n",
        "train_df['ImageID'] = train_df['ImageID'].apply(append_ext)\n",
        "val_df['ImageID'] = val_df['ImageID'].apply(append_ext)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VgzCC4rPF8fb",
        "outputId": "1dff2728-541a-4c9b-cc51-f7b232f4c870"
      },
      "source": [
        "# Looking into to make sure how the changes are \n",
        "train_df['ImageID'][0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJtWeHW8GHeA"
      },
      "source": [
        "# Creating Data generator for our data \n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1/255.)\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1 / 255.)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50OAns5oaytY",
        "outputId": "1945f70f-5ff7-45fa-dd90-8f44cfe4681c"
      },
      "source": [
        "# Now it's time to import our data into the generator \n",
        "\n",
        "train_data = train_datagen.flow_from_dataframe(dataframe= train_df , \n",
        "                                               directory = train_dir , \n",
        "                                               x_col = 'ImageID' , \n",
        "                                               y_col = 'label' , \n",
        "                                               target_size = (224 , 224) , \n",
        "                                               class_mode = 'binary')\n",
        "\n",
        "val_data = val_datagen.flow_from_dataframe(dataframe = val_df , \n",
        "                                           directory = val_dir , \n",
        "                                           x_col = 'ImageID' , \n",
        "                                           y_col = 'label' , \n",
        "                                           target_size = (224 , 224) , \n",
        "                                           class_mode = 'binary')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40000 validated image filenames belonging to 2 classes.\n",
            "Found 4000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kVX67G3dI2p"
      },
      "source": [
        "But here is the tricky part, the data augmentation will run on CPU if I am gonna use `ImageDataGenerator` which will slow up the entire process. By using `image_dataset_from_directory` at further we could create data augmentation as an layer and make the augmentation process run on GPU. \n",
        "\n",
        "Ima try If I can do that by using `ImageDataGenerator`, still not sure how it's gonna go. Experiment! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFvp5cRobgi4"
      },
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "data_augmentation_layer = tf.keras.Sequential([\n",
        "  preprocessing.RandomWidth(0.2), \n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomFlip() , \n",
        "  preprocessing.RandomHeight(0.2)\n",
        "])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKw7QTQ-b24Q"
      },
      "source": [
        "Let's build a baseline and see how it goes! Will build: \n",
        "- A model which has no data augmentation, just from a ImageDataGenerator with Transfer Learning (EfficientNetB0) and run for few epochs. \n",
        "- A experimentation model which does have augmentation like a layer, but unlike generator gotta add this inside the model to make it run on GPU. \n",
        "- If the above doesn't work, gotta add augmentation in the Datagenerator, and train a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fPqy4e5hMBz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}